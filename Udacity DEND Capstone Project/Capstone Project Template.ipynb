{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# DEND Udacity Project Capstone US Immigration\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project perform ETL Operations on Udacity provided I94 Immigration and Demographics datasets using Spark, Python, SQL. This notebook performs Exploratory Data Analysis on used datasets.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import os\n",
    "import tools as tools\n",
    "import etl as etl\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "* I plan to create a datalake about immigrants destinations in US. I will gather data from 4 sources. I will load data into staging dataframes, clean raw data, write it to parquet files and perform an ETL process using a Spark cluster. Then i will write the data into Fact & Dimension tables to form star schema. \n",
    "\n",
    "*Tools/Technologies*:\n",
    "- `Python 3.7` is used for this project as it is the latest compatible version with `Pyspark`. I've used type hinting as well.\n",
    "- `Aparch Spark (Pyspark)`: I've chosen Apache Spark for this project due to it's parallelism and ability to handle large datasets. Immigrations full dataset contains ~40MM rows. I've used a mix of Pyspark's SQL and python libraries in this project.\n",
    "- Apart these two main technologies, `Pandas` was used during EDA phase and `Parquet` is used to save output from ETL process in columnar format for better aggregate operations.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? \n",
    "* **I94 Immigration Data**: This data comes from US National Tourism and Trade Office. Dataset consists of 12 files containing data for each month. Each file has around 3 million rows and 28 columns. A dictionay explaining columns is included at I94_SAS_Labels_Descriptions.SAS. Check the sample data at immigration_data_sample.csv. **NOTE**: I've used sample sas dataset provided in sas_data dir in workspace by Udacity. This data contains ~3MM rows which satisfies the requirement of at least 1MM rows. It contains data for April 2016 only.\n",
    "* **World Temperature Data**: This dataset comes from Kaggle and includes the temperatures of various cities in the world.\n",
    "* **U.S. City Demographic Data**: This data comes from OpenSoft. \n",
    "* **Airport Code Table**: This is a simple table of airport codes and corresponding cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\")\\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0,saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "        .config(\"spark.python.worker.memory\", \"15g\")\\\n",
    "        .enableHiveSupport().getOrCreate()\n",
    "\n",
    "df_spark = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_immi_sample = pd.read_csv('immigration_data_sample.csv')\n",
    "df_immi_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# World Temperature Data\n",
    "temperaturefname = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df = pd.read_csv(temperaturefname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# U.S. City Demographic Data\n",
    "demographicfname = 'us-cities-demographics.csv'\n",
    "demographic_df = pd.read_csv(demographicfname, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airpotcodefname = 'airport-codes_csv.csv'\n",
    "airport_df = pd.read_csv(airpotcodefname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark.createOrReplaceTempView(\"immigration_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "* Refer to the \"Explore and Assess the Data\" notebook for data exploration and analysis\n",
    "#### Cleaning Steps\n",
    "* Drop columns containing over 95% missing values\n",
    "* Drop duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping missing data...\n",
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with over 95% missing values\n",
    "clean_temperature = tools.eliminate_column_missing_data(temperature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicate data...\n",
      "Drops 0 columns\n",
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "clean_temperature = tools.drop_duplicate_rows(clean_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping missing data...\n",
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with over 95% missing values\n",
    "clean_airport_codes = tools.eliminate_column_missing_data(airport_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicate data...\n",
      "Drops 0 columns\n",
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "clean_airport_codes = tools.drop_duplicate_rows(airport_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicate data...\n",
      "Drops 0 columns\n",
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "# When data df spark too large can meet error Java Heap when using eliminate_column_missing_data, so we will clean by spark tools.\n",
    "clean_immigration = tools.drop_duplicate_rows(df_immi_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping missing data...\n",
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with over 95% missing values\n",
    "clean_demographics = tools.eliminate_column_missing_data(demographic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicate data...\n",
      "Drops 0 columns\n",
      "Cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "clean_demographics = tools.drop_duplicate_rows(clean_demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model:\n",
    "\n",
    "**The Business Process: Immigration department follows their business process of migrants into country. This process generates events which are captured and translated to fact table.**\n",
    "\n",
    "**Identify the Dimensions:**\n",
    "1. dim_visa\n",
    "2. dim_temperature\n",
    "3. dim_country\n",
    "4. dim_state\n",
    "5. dim_time\n",
    "6. dim_airport\n",
    "7. dim_port\n",
    "**Identify the Facts:**\n",
    "1. fact_immigration\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Load data into staging tables\n",
    "2. Create Dimension tables\n",
    "3. Create Fact tables\n",
    "4. Write data into parquet files\n",
    "5. Perform data quality checks\n",
    "6. Perform data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "output_path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Staging data\n",
    "df_countries = pd.read_csv('countries.csv')\n",
    "df_ports = pd.read_csv('ports.csv')\n",
    "df_visas = pd.read_csv('visas.csv')\n",
    "df_states = pd.read_csv('states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: float (nullable = true)\n",
      " |-- i94yr: float (nullable = true)\n",
      " |-- i94mon: float (nullable = true)\n",
      " |-- i94cit: float (nullable = true)\n",
      " |-- i94res: float (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: float (nullable = true)\n",
      " |-- i94mode: float (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: float (nullable = true)\n",
      " |-- i94bir: float (nullable = true)\n",
      " |-- i94visa: float (nullable = true)\n",
      " |-- count: float (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: float (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: float (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: float (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create immigration schema\n",
    "df_spark = df_spark.withColumn(\"cicid\",df_spark.cicid.cast(FloatType()))\\\n",
    "                   .withColumn(\"i94yr\",df_spark.i94yr.cast(FloatType()))\\\n",
    "                   .withColumn(\"i94mon\",df_spark.i94mon.cast(FloatType()))\\\n",
    "                   .withColumn(\"i94cit\",df_spark.i94cit.cast(FloatType()))\\\n",
    "                   .withColumn(\"i94res\",df_spark.i94res.cast(FloatType()))\\\n",
    "                   .withColumn(\"arrdate\",df_spark.arrdate.cast(FloatType()))\\\n",
    "                   .withColumn(\"i94mode\",df_spark.i94mode.cast(FloatType()))\\\n",
    "                   .withColumn(\"depdate\",df_spark.depdate.cast(FloatType()))\\\n",
    "                   .withColumn(\"i94bir\",df_spark.i94bir.cast(FloatType()))\\\n",
    "                   .withColumn(\"i94visa\",df_spark.i94visa.cast(FloatType()))\\\n",
    "                   .withColumn(\"count\",col(\"count\").cast(FloatType()))\\\n",
    "                   .withColumn(\"biryear\",df_spark.biryear.cast(FloatType()))\\\n",
    "                   .withColumn(\"insnum\",df_spark.insnum.cast(FloatType()))\\\n",
    "                   .withColumn(\"admnum\",df_spark.admnum.cast(FloatType()))\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create schema for temperature\n",
    "temperature_schema = StructType([StructField(\"dt\", StringType(), True)\\\n",
    "                          ,StructField(\"AverageTemperature\", FloatType(), True)\\\n",
    "                          ,StructField(\"AverageTemperatureUncertainty\", FloatType(), True)\\\n",
    "                          ,StructField(\"City\", StringType(), True)\\\n",
    "                          ,StructField(\"Country\", StringType(), True)\\\n",
    "                          ,StructField(\"Latitude\", StringType(), True)\\\n",
    "                          ,StructField(\"Longitude\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create schema for temperature\n",
    "temperature_spark = spark.read.csv(temperaturefname, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: float (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: float (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_spark = temperature_spark.withColumn(\"AverageTemperature\",col(\"AverageTemperature\").cast(FloatType()))\\\n",
    "                                     .withColumn(\"AverageTemperatureUncertainty\",col(\"AverageTemperatureUncertainty\").cast(FloatType()))\n",
    "temperature_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create schema for demographics\n",
    "demographics_schema = StructType([StructField(\"City\", StringType(), True)\\\n",
    "                        ,StructField(\"State\", StringType(), True)\\\n",
    "                        ,StructField(\"Median Age\", FloatType(), True)\\\n",
    "                        ,StructField(\"Male Population\", FloatType(), True)\\\n",
    "                        ,StructField(\"Female Population\", FloatType(), True)\\\n",
    "                        ,StructField(\"Total Population\", IntegerType(), True)\\\n",
    "                        ,StructField(\"Number of Veterans\", FloatType(), True)\\\n",
    "                        ,StructField(\"Foreign-born\", FloatType(), True)\\\n",
    "                        ,StructField(\"Average Household Size\", FloatType(), True)\\\n",
    "                        ,StructField(\"State Code\", StringType(), True)\\\n",
    "                        ,StructField(\"Race\", StringType(), True)\\\n",
    "                        ,StructField(\"Count\", IntegerType(), True)])\n",
    "\n",
    "demographics_spark = spark.createDataFrame(clean_demographics, schema=demographics_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: float (nullable = true)\n",
      " |-- Male Population: float (nullable = true)\n",
      " |-- Female Population: float (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: float (nullable = true)\n",
      " |-- Foreign-born: float (nullable = true)\n",
      " |-- Average Household Size: float (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create schema for airport\n",
    "airport_codes_schema = StructType([StructField(\"ident\", StringType(), True)\\\n",
    "                        ,StructField(\"type\", StringType(), True)\\\n",
    "                        ,StructField(\"name\", StringType(), True)\\\n",
    "                        ,StructField(\"elevation_ft\", FloatType(), True)\\\n",
    "                        ,StructField(\"continent\", StringType(), True)\\\n",
    "                        ,StructField(\"iso_country\", StringType(), True)\\\n",
    "                        ,StructField(\"iso_region\", StringType(), True)\\\n",
    "                        ,StructField(\"municipality\", StringType(), True)\\\n",
    "                        ,StructField(\"gps_code\", StringType(), True)\\\n",
    "                        ,StructField(\"iata_code\", StringType(), True)\\\n",
    "                        ,StructField(\"local_code\", StringType(), True)\\\n",
    "                        ,StructField(\"coordinates\", StringType(), True)])\n",
    "airport_codes_spark = spark.createDataFrame(clean_airport_codes, schema=airport_codes_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: float (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create schema for airport\n",
    "country_spark = spark.createDataFrame(df_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: long (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create schema for port\n",
    "port_schema = StructType([StructField(\"code\", StringType(), True)\\\n",
    "                        ,StructField(\"location\", StringType(), True)\\\n",
    "                        ,StructField(\"state\", StringType(), True)])\n",
    "port_spark = spark.createDataFrame(df_ports, schema=port_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "port_spark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "***create dim_visa***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "visa_df = etl.create_dim_visa(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table visa to data/visa\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "# write parquet files\n",
    "tools.write_to_parquet(visa_df, output_path, 'visa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visa_id</th>\n",
       "      <th>i94visa</th>\n",
       "      <th>visatype</th>\n",
       "      <th>visapost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8901</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F1</td>\n",
       "      <td>PRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>F1</td>\n",
       "      <td>OTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52212</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B2</td>\n",
       "      <td>ALB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B1</td>\n",
       "      <td>LUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>SHG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visa_id  i94visa visatype visapost\n",
       "0     8901      3.0       F1      PRS\n",
       "1    37333      3.0       F1      OTT\n",
       "2    52212      2.0       B2      ALB\n",
       "3    69139      1.0       B1      LUS\n",
       "4   159998      1.0        I      SHG"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visa = spark.read.parquet(\"data/visa\")\n",
    "visa.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "***create dim_country***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_df = etl.create_dim_country(country_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table country to data/country\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "# write parquet files\n",
    "tools.write_to_parquet(country_df, output_path, 'country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country_code: long (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country = spark.read.parquet(\"data/country\")\n",
    "country.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "***create dim_state***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_df = etl.create_dim_state(demographics_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table state to data/state\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "# write parquet files\n",
    "tools.write_to_parquet(state_df, output_path, 'state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>total_population</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DC</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>33.80</td>\n",
       "      <td>3361140</td>\n",
       "      <td>1598525.0</td>\n",
       "      <td>1762615.0</td>\n",
       "      <td>475585.0</td>\n",
       "      <td>2.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>32.74</td>\n",
       "      <td>2882889</td>\n",
       "      <td>1400724.0</td>\n",
       "      <td>1482165.0</td>\n",
       "      <td>307753.0</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TN</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>34.31</td>\n",
       "      <td>10690165</td>\n",
       "      <td>5124189.0</td>\n",
       "      <td>5565976.0</td>\n",
       "      <td>900149.0</td>\n",
       "      <td>2.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LA</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>34.63</td>\n",
       "      <td>6502975</td>\n",
       "      <td>3134990.0</td>\n",
       "      <td>3367985.0</td>\n",
       "      <td>417095.0</td>\n",
       "      <td>2.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>35.04</td>\n",
       "      <td>22497710</td>\n",
       "      <td>11137275.0</td>\n",
       "      <td>11360435.0</td>\n",
       "      <td>3411565.0</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code                 state  median_age  total_population  \\\n",
       "0         DC  District of Columbia       33.80           3361140   \n",
       "1         AR              Arkansas       32.74           2882889   \n",
       "2         TN             Tennessee       34.31          10690165   \n",
       "3         LA             Louisiana       34.63           6502975   \n",
       "4         AZ               Arizona       35.04          22497710   \n",
       "\n",
       "   male_population  female_population  foreign_born  average_household_size  \n",
       "0        1598525.0          1762615.0      475585.0                    2.24  \n",
       "1        1400724.0          1482165.0      307753.0                    2.53  \n",
       "2        5124189.0          5565976.0      900149.0                    2.46  \n",
       "3        3134990.0          3367985.0      417095.0                    2.47  \n",
       "4       11137275.0         11360435.0     3411565.0                    2.77  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = spark.read.parquet(\"data/state\")\n",
    "state.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "***create dim_time***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_df = etl.create_dim_time(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table time to data/time\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "# write parquet files\n",
    "tools.write_to_parquet(time_df, output_path, 'time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrdate</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20571.0</td>\n",
       "      <td>2016-04-27</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20567.0</td>\n",
       "      <td>2016-04-23</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20564.0</td>\n",
       "      <td>2016-04-20</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20574.0</td>\n",
       "      <td>2016-04-30</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20560.0</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   arrdate        date  day  month  year  week  weekday\n",
       "0  20571.0  2016-04-27   27      4  2016    17        4\n",
       "1  20567.0  2016-04-23   23      4  2016    16        7\n",
       "2  20564.0  2016-04-20   20      4  2016    16        4\n",
       "3  20574.0  2016-04-30   30      4  2016    17        7\n",
       "4  20560.0  2016-04-16   16      4  2016    15        7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = spark.read.parquet(\"data/time\")\n",
    "time.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "***create dim_airport***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport_df = etl.create_dim_airport(airport_codes_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table airport to data/airport\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "# write parquet files\n",
    "tools.write_to_parquet(airport_codes_spark, output_path, 'airport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport = spark.read.parquet(\"data/airport\")\n",
    "airport.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "***create dim_port***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "port_df = etl.create_dim_port(port_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table port to data/port\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "# write parquet files\n",
    "tools.write_to_parquet(port_df, output_path, 'port')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>port_code</th>\n",
       "      <th>city</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPT</td>\n",
       "      <td>EASTPORT MUNICIPAL</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPA</td>\n",
       "      <td>ST PAMPILE</td>\n",
       "      <td>ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GTF</td>\n",
       "      <td>Collapsed into INT</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WSB</td>\n",
       "      <td>WARROAD INTL</td>\n",
       "      <td>SPB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRE</td>\n",
       "      <td>GREAT FALLS</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  port_code                city state_code\n",
       "0       EPT  EASTPORT MUNICIPAL         ME\n",
       "1       SPA          ST PAMPILE         ME\n",
       "2       GTF  Collapsed into INT         MN\n",
       "3       WSB        WARROAD INTL        SPB\n",
       "4       GRE         GREAT FALLS         MT"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = spark.read.parquet(\"data/port\")\n",
    "port.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "***create dim_temperature***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_staging = etl.create_staging_temperature(temperature_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table staging_temperature to data/staging_temperature\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "# write parquet files\n",
    "tools.write_to_parquet(temperature_staging, output_path, 'staging_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_id</th>\n",
       "      <th>country</th>\n",
       "      <th>average_temperature</th>\n",
       "      <th>average_temperature_uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1675037245440</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>9.10</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1675037245441</td>\n",
       "      <td>Moldova</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1675037245442</td>\n",
       "      <td>Congo (Democratic Republic Of The)</td>\n",
       "      <td>23.24</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1649267441664</td>\n",
       "      <td>Bosnia And Herzegovina</td>\n",
       "      <td>10.45</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1236950581248</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>26.57</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature_id                             country  average_temperature  \\\n",
       "0   1675037245440                      United Kingdom                 9.10   \n",
       "1   1675037245441                             Moldova                 8.67   \n",
       "2   1675037245442  Congo (Democratic Republic Of The)                23.24   \n",
       "3   1649267441664              Bosnia And Herzegovina                10.45   \n",
       "4   1236950581248                United Arab Emirates                26.57   \n",
       "\n",
       "   average_temperature_uncertainty  \n",
       "0                             1.59  \n",
       "1                             1.51  \n",
       "2                             0.70  \n",
       "3                             1.57  \n",
       "4                             0.84  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_staging = spark.read.parquet(\"data/staging_temperature\")\n",
    "temperature_staging.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# merge countries and temperature data.\n",
    "country_temp = country.select([\"*\"])\\\n",
    "            .join(temperature_staging, (upper(trim(country.country_name)) == upper(trim(temperature_staging.country))), how='full')\\\n",
    "            .select([country.country_code, country.country_name, temperature_staging.temperature_id, temperature_staging.average_temperature, temperature_staging.average_temperature_uncertainty])\\\n",
    "            .dropna(subset=\"temperature_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table temperature to data/temperature\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "# write parquet files\n",
    "tools.write_to_parquet(country_temp, output_path, 'temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = spark.read.parquet(\"data/temperature\")\n",
    "temperature.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "***create fact_immigration***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# (spark, immigration_df, countries_df, states_df, ports_df, visas_df, temperature_df, airports_df, time_df)\n",
    "immigration = etl.create_fact_immigration(spark, df_spark, country, state, port, visa, temperature, airport, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sum data of immigration\n",
    "immigration.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT cicid)|\n",
      "+---------------------+\n",
      "|              3096313|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check sum data of immigration\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        count(DISTINCT si.cicid)\n",
    "    FROM staging_immigration_data si \n",
    "    LEFT JOIN staging_states_data ss ON si.i94addr = ss.state_code \n",
    "    LEFT JOIN staging_visas_data sv ON \n",
    "    (si.i94visa = sv.i94visa\n",
    "    AND si.visatype = sv.visatype\n",
    "    AND si.visapost = sv.visapost)\n",
    "    LEFT JOIN staging_ports_data sp ON sp.port_code = si.i94port \n",
    "    LEFT JOIN staging_temperature_data st ON si.i94res = st.country_code \n",
    "    LEFT JOIN staging_countries_data sc ON sc.country_code = si.i94res \n",
    "    LEFT JOIN staging_airports_data sa ON sa.ident = si.i94port \n",
    "    LEFT JOIN staging_time_data std ON std.arrdate = si.arrdate  \n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing table fact_immigration to data/fact_immigration\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "# write parquet files\n",
    "tools.write_to_parquet(immigration, output_path, 'fact_immigration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096313"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration = spark.read.parquet(\"data/fact_immigration\")\n",
    "immigration.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**For Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration.createOrReplaceTempView('fact_immigration')\n",
    "temperature.createOrReplaceTempView('dim_temperature')\n",
    "country.createOrReplaceTempView('dim_country')\n",
    "state.createOrReplaceTempView('dim_state')\n",
    "port.createOrReplaceTempView('dim_port')\n",
    "visa.createOrReplaceTempView('dim_visa')\n",
    "airport.createOrReplaceTempView('dim_airport')\n",
    "time.createOrReplaceTempView('dim_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+----------------+----------+\n",
      "|port_code|immigrant_visits|            city|state_code|\n",
      "+---------+----------------+----------------+----------+\n",
      "|      NYC|          485916|        NEW YORK|        NY|\n",
      "|      MIA|          343941|           MIAMI|        FL|\n",
      "|      LOS|          310163|     LOS ANGELES|        CA|\n",
      "|      SFR|          152586|   SAN FRANCISCO|        CA|\n",
      "|      ORL|          149195|         ORLANDO|        FL|\n",
      "|      HHW|          142720|        HONOLULU|        HI|\n",
      "|      NEW|          136122|NEWARK/TETERBORO|        NJ|\n",
      "|      CHI|          130564|         CHICAGO|        IL|\n",
      "|      HOU|          101481|         HOUSTON|        TX|\n",
      "|      FTL|           95977| FORT LAUDERDALE|        FL|\n",
      "+---------+----------------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which city was most visited in a specific month?\n",
    "# This data is from April file, let's try for it\n",
    "# numeric code for April is 4\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        tvc.port_code,\n",
    "        tvc.immigrant_visits,\n",
    "        dp.city,\n",
    "        dp.state_code\n",
    "    FROM\n",
    "        (SELECT \n",
    "            fi.port_code AS port_code, \n",
    "            COUNT(*) AS immigrant_visits\n",
    "        FROM fact_immigration fi \n",
    "        WHERE fi.i94mon = 4\n",
    "        GROUP BY fi.port_code\n",
    "        ORDER BY immigrant_visits DESC\n",
    "        LIMIT 10\n",
    "        ) AS tvc \n",
    "    JOIN dim_port dp\n",
    "        ON dp.port_code = tvc.port_code\n",
    "    ORDER BY tvc.immigrant_visits DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+------------+--------------------+\n",
      "|origin_country_code|country_visitors|country_code|        country_name|\n",
      "+-------------------+----------------+------------+--------------------+\n",
      "|                135|          368421|         135|      UNITED KINGDOM|\n",
      "|                209|          249167|         209|               JAPAN|\n",
      "|                245|          185609|         245|          CHINA, PRC|\n",
      "|                111|          185339|         111|              FRANCE|\n",
      "|                582|          179603|         582|MEXICO Air Sea, a...|\n",
      "|                112|          156613|         112|             GERMANY|\n",
      "|                276|          136312|         276|         SOUTH KOREA|\n",
      "|                689|          134907|         689|              BRAZIL|\n",
      "|                438|          112407|         438|           AUSTRALIA|\n",
      "|                213|          107193|         213|               INDIA|\n",
      "+-------------------+----------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#From which country (or countries) travelers originate? Top countries of origin.\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM\n",
    "        (SELECT \n",
    "            fi.country_code AS origin_country_code, \n",
    "            COUNT(*) AS country_visitors\n",
    "        FROM fact_immigration fi \n",
    "        GROUP BY fi.country_code\n",
    "        ORDER BY country_visitors DESC\n",
    "        LIMIT 10\n",
    "        ) AS tcv\n",
    "    JOIN dim_country dc\n",
    "        ON tcv.origin_country_code = dc.country_code\n",
    "    ORDER BY country_visitors DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+------------+--------------------+\n",
      "|origin_country_code|student_visitors|country_code|        country_name|\n",
      "+-------------------+----------------+------------+--------------------+\n",
      "|                245|           32284|         245|          CHINA, PRC|\n",
      "|                582|           31031|         582|MEXICO Air Sea, a...|\n",
      "|                213|           22485|         213|               INDIA|\n",
      "|                689|           14044|         689|              BRAZIL|\n",
      "|                691|            6748|         691|            COLOMBIA|\n",
      "|                251|            6147|         251|              ISRAEL|\n",
      "|                135|            4261|         135|      UNITED KINGDOM|\n",
      "|                687|            4196|         687|           ARGENTINA|\n",
      "|                107|            4167|         107|              POLAND|\n",
      "|                264|            3892|         264|              TURKEY|\n",
      "+-------------------+----------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top countries from where students are coming?\n",
    "# visa_type = B1(SAS file)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM\n",
    "        (SELECT \n",
    "            fi.country_code AS origin_country_code, \n",
    "            COUNT(*) AS student_visitors\n",
    "        FROM fact_immigration fi\n",
    "        WHERE fi.visa_type = 'B1'\n",
    "        GROUP BY fi.country_code\n",
    "        ORDER BY student_visitors DESC\n",
    "        LIMIT 10\n",
    "        ) AS tcv\n",
    "    JOIN dim_country dc\n",
    "        ON tcv.origin_country_code = dc.country_code\n",
    "    ORDER BY student_visitors DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality check passed for Immigrations fact with record_count: 3096313 records.\n",
      "Data quality check passed for Dim time with record_count: 30 records.\n",
      "Data quality check passed for Dim airport with record_count: 55075 records.\n",
      "Data quality check passed for Dim temperature with record_count: 159 records.\n",
      "Data quality check passed for Dim port with record_count: 660 records.\n",
      "Data quality check passed for Dim visa with record_count: 2101 records.\n",
      "Data quality check passed for Dim state with record_count: 47 records.\n",
      "Data quality check passed for Dim country with record_count: 289 records.\n",
      "All tables passed.\n"
     ]
    }
   ],
   "source": [
    "tools.quality_check(immigration,\n",
    "                  country,\n",
    "                  time,\n",
    "                  airport,\n",
    "                  temperature,\n",
    "                  visa,\n",
    "                  port,\n",
    "                  state,\n",
    "                  spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**refer to Data_Dictionary.txt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**1. Clearly state the rationale for the choice of tools and technologies for the project.**\n",
    "- `Python 3.7` is used for this project as it is the latest compatible version with `Pyspark`. I've used type hinting as well.\n",
    "- `Aparch Spark (Pyspark)`: I've chosen Apache Spark for this project due to it's parallelism and ability to handle large datasets. Immigrations full dataset contains ~40MM rows. I've used a mix of Pyspark's SQL and python libraries in this project.\n",
    "- Apart these two main technologies, `Pandas` was used during EDA phase and `Parquet` is used to save output from ETL process in columnar format for better aggregate operations.\n",
    "- `Pandas` due to its convenient dataframe manipulation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**2. Propose how often the data should be updated and why.**\n",
    "\n",
    "- The immigration (i94) data set is updated monthly, hence all relevant data should be updated monthly as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**3. Write a description of how you would approach the problem differently under the following scenarios:**\n",
    "- When data increased by 100x: Our data would bs store in AWS S3. Still use Spark as it as our data processing platform since it is the best suited for large datasets\n",
    "- When need to scheduled data pipelines, We can use Apache Airflow to perform ETL and data quality validation\n",
    "- When database need to access by 100+ people: We can use postgres database on a redshift cluster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
